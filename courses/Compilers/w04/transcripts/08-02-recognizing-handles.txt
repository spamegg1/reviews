Welcome back, in this video we're gonna talk about the key ideas behind techniques
for recognizing handles. There is good news and bad news when it comes to
recognizing handles. The bad news is that there is no known efficient algorithm that
recognizes handles in general. So for an arbitrary grammar, we don't have a fast
way to find the handles when we're parsing. The good news is that there are
heuristics for guessing handles, and for some context free grammars, for some
fairly large classes of context free grammars, these heuristics always identify
the handles correctly. We can illustrate the situation with a Venn diagram. If we
start with a set of all context free grammars, then the unambiguous context
free grammars are a sub-set of those, and then an even smaller set are called the
LR(k) grammars. And here, just to remind you, 'l' stands for left to right scan,
'r' stands for rightmost variation, and 'k' stands for the number of tokens of
look ahead. Now the LRK grammars are one of the most general deterministic families
of deterministic grammars that we know of. But those aren't the ones that are
actually used in practice. Most of the bottom up tools that are practical, use
what are called the LALRK grammars, which are a subset of the LRK grammars. And then
what we're gonna talk mostly about is a simplification of those called the simple
LR grammars, or the SLRK context free grammars. And these containment
relationships or [inaudible] that is, there are grammars that are [inaudible]. R
k but not s l r k, for every k, and similarly there are grammars that are l r
k for every k that are not l a l r k. As we've already said, it's not obvious how
to detect handles. So, what does the parser know? Well, it sees the stack. At
each step it knows the stack that it has already, constructed. And so let's see how
much progress we can make just thinking about, what information we can get from
the stack. So here's a definition. We're going to say that alpha is a viable
prefix. If there is some omega, such that alpha bar omega is a configuration, a
valid configuration of a shift reduce parse. Now keep in mind that the alpha
here. This is the stack. And the omega here is the rest of the input. And what
does that means? That means the parser knows this part. The parser knows alpha,
it doesn't know much of omega. It can do some look-ahead, it can look at a small
prefix of omega, usually just one token, but it certainly doesn't know the whole
thing. So what does a viable prefix mean? Well, a viable prefix is a string that
does not extend past the right end of the handle. And the reason we call it a viable
prefix is because it is a prefix of the handle. So as long as the parser has
viable prefixes on the stack, no parsing error has been detected. And really the
definition is just giving a name to something, it's not anything very deep,
the fact that alpha bar omega is, is viable, that's just saying we haven't
encountered an error. That this is some state of a shift reduce parse. It hasn't
said yet how we're going to identity it or anything like that; it's just saying that
these are the valid states of shift reduced parse. Now the definition is
useful in one way if it bring us to the last important fact, important fact number
three about bottom up parsing. In this effort, any grammar, the set of viable
prefixes is a regular language, and this is really an amazing fact, and one that's
going to take us a little while to demonstrate, but this is the key to bottom
up parsing. At least all the bottom up parsing tools are based on this fact, that
the set of viable prefix can be recognized by a finite automaton. So, we're going to
show how to compute this automaton that accepts the viable prefixes, but first
we're going to need a number of additional definitions. The first definition we need
is the idea of an item. Now an item is a production that just has a dot somewhere
on the right hand side. So here's an example. Let's take the production, T goes
to open paren, E closed paren. What we're going to do is we're just gonna put the
dot in eve ry possible position on the right hand side. So we'll have one item
where the dot is all the way at the left end. We'll have one where the dot is all
the way at the right end. And then we'll have, items where the dot is between every
pair of consecutive symbols. So in this case, there are four items for the
production. One special case is, what do we do with epsilon productions? Well, for
an epsilon production, there is no, there are no symbols on the right hand side.
We'll just say there is one item, X goes to dot. And these items, you'll see them
referred to, if you, if you look in help, pages and in the literature, as, the LR
zero items. Now we're ready to discuss how we recognize viable prefixes. And the
problem is that the stack has only bits and pieces of the right hand side of
productions. In general most of the time, we don't have a complete right hand side
on top of the stack. Most of the time, we only have a part of the right hand side.
And. It turns out that what is on the stack is actually not just random it's,
it's it actually has a very special structure. In, in these bits and pieces
are always prefixes of right hand sides of productions. That is in any successful
parse what is on the stack always has to be a prefix of the right hand side of some
production or productions. Let's take a look at an example. Let's consider the
input open paren, [inaudible] closed paren. And here's one of our favorite
grammars. Now, this configurations, where I have open paren E, [inaudible], on the
stack. Remember that this is our stack. And we have the close [inaudible] in the
input. This is actually a state or a valid state of a shift [inaudible]. And you can
see here that, open paren E is a prefix of the production. T goes to open paren E,
close paren. And after we shift the remaining close paren onto the stack, then
we'll have the complete right hand side, and it will be ready to reduce. So this is
where the items come in. The item, T goes to open paren E. Dot, closed paren. This
describes this state of affairs. I t says that so far, we have seen open paren E of
this production. And we're hoping in the future to see the closed paren. So another
way of thinking about it is that this item records the fact that we're working on
this production. And then so far we've seen this much. Everything to the left of
the dot is what we've already seen and is what is on the stack and. What is to the
right of the dot is what we're waiting to see before we could possibly reduce. And
we may or may not see that, remember, the parser doesn't know the input. In this
case of course, it's the very next, next symbol and so it can see in the
look-ahead, but you know at this point in time the parser doesn't know for sure
what's coming up and, you know, and, and, if this dot were further to the left there
might be many, many more symbols that we had to go, before we could perform the
reduction. So anyway, what's to the left of that records what we've already seen.
And what is to the right of the dot, says that what we are waiting to see on the
stack, before we can perform a reduction. And now we could talk about the structure
of the stack. So you see it's not just arbitrary collections of symbols. In fact,
it has this very particular structure. So the stack is actually a stack of prefixes
of right hand sides. So the stack always has this organization where there's a
bunch of prefixes, stacked up, literally stacked up on the stack. And what's going
to happen is that the ice prefix, if you were to pick a prefix out of this stack of
prefixes, While that must be the prefix of some production. Okay. The right hand side
of sum production And what that means is that, that prefix, that [inaudible] prefix
on the stack, will eventually reduce to the left hand side of that production. So
it will eventually reduce to, XI in this case. And then that XI has to be Part of
the missing suffix, of the prefix that is below it on the stack. So if I look at the
previous prefix the one that's right below, prefix [inaudible] on the stack
Then when I perform this reducti on that XI needs to extend that prefix to be
closer to a complete right hand side of that particular reduction. Okay so in
particular there's going to be some production. That is going to; already have
a portion of its right hand side on the stack. So prefix of I minus one. And X I
is going to extend that prefix, and then there's gonna be some more stuff possibly
that we're waiting to see, even after the X I is put there. And recursively, all the
prefixes above prefix K eventually have to reduce to the missing part of the right
hand side of prefix K, the alpha K that goes on the right hand side. [inaudible]
This image, you have a stack of prefixes we're always working on the top-most
prefix on the stack, so you will be always working here on the right and shifting and
reducing, but every time we perform a reduction. That has to extend the prefix
immediately below it on the stack. And when these, when a bunch of prefixes have
been removed from the stack through reductions, then we, when we get to work
on the prefixes that are lower in the stack. So let's illustrate this idea with
an example. So here is another input string, and we're gonna use the same
grammar. You can, you can rewind if you want to see the grammar again. But let's
consider this state where we have open paren, [inaudible] star on the stack. And
we have int, close paren remaining in the input, 'kay? And so what items would
record, what is the, what is the stack structure here and how do the items record
it? Well let's start here at the bottom, let's actually work from the bottom up. So
we have in start the top of our stack, so we this is the right hand side that we're
currently working on, and that would be a prefix to this production T goes to int
star T. Okay? So what this says is that we're looking you know, we, we've seen in
stars so far, and we're waiting to see [inaudible]. I'm not showing the items,
but I'm just showing the productions that this is eventually going to use. Now, the
one that's below it here, the, the prefix that's below it o n the stack is right
here in between the open paren and the int. This one's an interesting case. It's
actually epsilon. So there's nothing there now on the stack. But eventually once the
int star has reduced to T. Okay? Then that T is going to reduce to E. And currently,
of course, there's not a T there at all. So we've only seen epsilon. We've seen
none of the prefix of this production on the stack. And then for the last
production, the one deepest in the stack, we're currently, we've currently seen an
open paren. And, we're w-, and we think we're working on this production. T goes
to open paren, E closed paren, alright? So when this E is produced, that will extend
this right hand side. And now we can record all of this with the stack of
items, T goes to open paren dot E, E goes to dot T, and T goes to N star dot T.
Okay, and we just record what we said on the previous slide, that so far, we see
the open paren of this production. We've seen nothing out of the right hand side of
this production, and we've seen N star so far of this production. And just notice
how the left hand side of each of these productions is going to eventually become
part of the right hand side of the. Of the right, part of the right hand side of the
production we are working on just below it in the stack. So when we've reduced this
instar T to T that will extend this production, when it reaches E that will
extend this production To summarize this video, we can say a little more precisely
how we go about recognizing viable prefixes. The crux of the problem is going
to be to recognize a sequence of partial right had sides of production. Where each
of those partial right hand sides can eventually reduce to part of the missing
suffix of its predecessor Next time, in the next video we're going to actually
give the algorithm for implementing this idea.